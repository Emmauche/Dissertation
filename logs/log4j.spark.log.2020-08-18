20/08/18 07:36:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/08/18 07:36:21 INFO SecurityManager: Changing view acls to: emmanuel
20/08/18 07:36:21 INFO SecurityManager: Changing modify acls to: emmanuel
20/08/18 07:36:21 INFO SecurityManager: Changing view acls groups to: 
20/08/18 07:36:21 INFO SecurityManager: Changing modify acls groups to: 
20/08/18 07:36:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(emmanuel); groups with view permissions: Set(); users  with modify permissions: Set(emmanuel); groups with modify permissions: Set()
20/08/18 07:36:24 INFO HiveConf: Found configuration file file:/home/emmanuel/spark/spark-3.0.0-bin-hadoop2.7/conf/hive-site.xml
20/08/18 07:36:24 INFO SparkContext: Running Spark version 3.0.0
20/08/18 07:36:24 INFO ResourceUtils: ==============================================================
20/08/18 07:36:24 INFO ResourceUtils: Resources for spark.driver:

20/08/18 07:36:24 INFO ResourceUtils: ==============================================================
20/08/18 07:36:24 INFO SparkContext: Submitted application: sparklyr
20/08/18 07:36:24 INFO SecurityManager: Changing view acls to: emmanuel
20/08/18 07:36:24 INFO SecurityManager: Changing modify acls to: emmanuel
20/08/18 07:36:24 INFO SecurityManager: Changing view acls groups to: 
20/08/18 07:36:24 INFO SecurityManager: Changing modify acls groups to: 
20/08/18 07:36:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(emmanuel); groups with view permissions: Set(); users  with modify permissions: Set(emmanuel); groups with modify permissions: Set()
20/08/18 07:36:25 INFO Utils: Successfully started service 'sparkDriver' on port 46389.
20/08/18 07:36:25 INFO SparkEnv: Registering MapOutputTracker
20/08/18 07:36:25 INFO SparkEnv: Registering BlockManagerMaster
20/08/18 07:36:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/08/18 07:36:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/08/18 07:36:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
20/08/18 07:36:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-32b8cdae-2036-465a-9dc6-bbcc202d7f58
20/08/18 07:36:25 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
20/08/18 07:36:26 INFO SparkEnv: Registering OutputCommitCoordinator
20/08/18 07:36:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/08/18 07:36:27 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
20/08/18 07:36:27 INFO SparkContext: Added JAR file:/home/emmanuel/R/x86_64-pc-linux-gnu-library/3.4/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:46389/jars/sparklyr-3.0-2.12.jar with timestamp 1597750587218
20/08/18 07:36:27 INFO Executor: Starting executor ID driver on host localhost
20/08/18 07:36:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36565.
20/08/18 07:36:27 INFO NettyBlockTransferService: Server created on localhost:36565
20/08/18 07:36:27 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/08/18 07:36:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 36565, None)
20/08/18 07:36:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36565 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 36565, None)
20/08/18 07:36:27 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 36565, None)
20/08/18 07:36:27 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 36565, None)
20/08/18 07:36:29 INFO SharedState: loading hive config file: file:/home/emmanuel/spark/spark-3.0.0-bin-hadoop2.7/conf/hive-site.xml
20/08/18 07:36:29 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/emmanuel/R/Dissertation/spark-warehouse').
20/08/18 07:36:29 INFO SharedState: Warehouse path is 'file:/home/emmanuel/R/Dissertation/spark-warehouse'.
20/08/18 07:36:35 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
20/08/18 07:36:35 INFO HiveConf: Found configuration file file:/home/emmanuel/spark/spark-3.0.0-bin-hadoop2.7/conf/hive-site.xml
20/08/18 07:36:37 INFO SessionState: Created HDFS directory: /tmp/hive/emmanuel
20/08/18 07:36:37 INFO SessionState: Created local directory: /tmp/emmanuel
20/08/18 07:36:37 INFO SessionState: Created HDFS directory: /tmp/hive/emmanuel/9640031d-9aca-4ab3-b17e-981feaaa0c21
20/08/18 07:36:37 INFO SessionState: Created local directory: /tmp/emmanuel/9640031d-9aca-4ab3-b17e-981feaaa0c21
20/08/18 07:36:37 INFO SessionState: Created HDFS directory: /tmp/hive/emmanuel/9640031d-9aca-4ab3-b17e-981feaaa0c21/_tmp_space.db
20/08/18 07:36:37 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/home/emmanuel/R/Dissertation/spark-warehouse
20/08/18 07:36:39 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
20/08/18 07:36:39 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
20/08/18 07:36:39 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
20/08/18 07:36:39 INFO ObjectStore: ObjectStore, initialize called
20/08/18 07:36:39 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
20/08/18 07:36:39 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
20/08/18 07:36:43 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
20/08/18 07:36:47 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
20/08/18 07:36:47 INFO ObjectStore: Initialized ObjectStore
20/08/18 07:36:47 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
20/08/18 07:36:47 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore emmanuel@127.0.1.1
20/08/18 07:36:47 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
20/08/18 07:36:48 INFO HiveMetaStore: Added admin role in metastore
20/08/18 07:36:48 INFO HiveMetaStore: Added public role in metastore
20/08/18 07:36:48 INFO HiveMetaStore: No user is added in admin role, since config is empty
20/08/18 07:36:49 INFO HiveMetaStore: 0: get_all_functions
20/08/18 07:36:49 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_all_functions	
20/08/18 07:36:49 INFO HiveMetaStore: 0: get_database: default
20/08/18 07:36:49 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 07:36:49 INFO HiveMetaStore: 0: get_database: global_temp
20/08/18 07:36:49 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: global_temp	
20/08/18 07:36:49 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
20/08/18 07:36:49 INFO HiveMetaStore: 0: get_database: default
20/08/18 07:36:49 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 07:36:49 INFO HiveMetaStore: 0: get_database: default
20/08/18 07:36:49 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 07:36:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/08/18 07:36:49 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/08/18 07:36:51 INFO CodeGenerator: Code generated in 440.083875 ms
20/08/18 07:36:51 INFO CodeGenerator: Code generated in 29.486127 ms
20/08/18 07:36:52 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 07:36:52 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:114) as input to shuffle 0
20/08/18 07:36:52 INFO DAGScheduler: Got job 0 (count at utils.scala:114) with 1 output partitions
20/08/18 07:36:52 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:114)
20/08/18 07:36:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
20/08/18 07:36:52 INFO DAGScheduler: Missing parents: List()
20/08/18 07:36:52 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:114), which has no missing parents
20/08/18 07:36:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
20/08/18 07:36:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
20/08/18 07:36:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36565 (size: 5.0 KiB, free: 912.3 MiB)
20/08/18 07:36:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1200
20/08/18 07:36:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 07:36:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/08/18 07:36:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
20/08/18 07:36:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
20/08/18 07:36:53 INFO Executor: Fetching spark://localhost:46389/jars/sparklyr-3.0-2.12.jar with timestamp 1597750587218
20/08/18 07:36:53 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:46389 after 47 ms (0 ms spent in bootstraps)
20/08/18 07:36:53 INFO Utils: Fetching spark://localhost:46389/jars/sparklyr-3.0-2.12.jar to /tmp/spark-06406bd7-240b-4c8d-8ead-d460bc7da82a/userFiles-f216aec5-214d-4c21-b6db-e3eabe89b5ad/fetchFileTemp2416026050789949982.tmp
20/08/18 07:36:53 INFO Executor: Adding file:/tmp/spark-06406bd7-240b-4c8d-8ead-d460bc7da82a/userFiles-f216aec5-214d-4c21-b6db-e3eabe89b5ad/sparklyr-3.0-2.12.jar to class loader
20/08/18 07:36:54 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 07:36:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 25 ms
20/08/18 07:36:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
20/08/18 07:36:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 1526 ms on localhost (executor driver) (1/1)
20/08/18 07:36:54 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/08/18 07:36:54 INFO DAGScheduler: ResultStage 1 (count at utils.scala:114) finished in 2.181 s
20/08/18 07:36:54 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 07:36:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
20/08/18 07:36:54 INFO DAGScheduler: Job 0 finished: count at utils.scala:114, took 2.349497 s
20/08/18 07:36:55 INFO HiveMetaStore: 0: get_database: default
20/08/18 07:36:55 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 07:36:55 INFO HiveMetaStore: 0: get_database: default
20/08/18 07:36:55 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 07:36:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/08/18 07:36:55 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/08/18 07:36:55 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 07:36:55 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:114) as input to shuffle 1
20/08/18 07:36:55 INFO DAGScheduler: Got job 1 (count at utils.scala:114) with 1 output partitions
20/08/18 07:36:55 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:114)
20/08/18 07:36:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
20/08/18 07:36:55 INFO DAGScheduler: Missing parents: List()
20/08/18 07:36:55 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:114), which has no missing parents
20/08/18 07:36:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
20/08/18 07:36:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
20/08/18 07:36:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36565 (size: 5.0 KiB, free: 912.3 MiB)
20/08/18 07:36:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
20/08/18 07:36:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 07:36:55 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/08/18 07:36:55 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
20/08/18 07:36:55 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
20/08/18 07:36:55 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 07:36:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/08/18 07:36:55 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
20/08/18 07:36:55 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 18 ms on localhost (executor driver) (1/1)
20/08/18 07:36:55 INFO DAGScheduler: ResultStage 3 (count at utils.scala:114) finished in 0.053 s
20/08/18 07:36:55 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 07:36:55 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/08/18 07:36:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
20/08/18 07:36:55 INFO DAGScheduler: Job 1 finished: count at utils.scala:114, took 0.069581 s
20/08/18 07:38:10 INFO HiveMetaStore: 0: get_database: default
20/08/18 07:38:10 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 07:38:10 INFO HiveMetaStore: 0: get_database: default
20/08/18 07:38:10 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 07:38:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/08/18 07:38:10 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/08/18 07:38:10 INFO SparkContext: Starting job: collect at utils.scala:41
20/08/18 07:38:10 INFO DAGScheduler: Job 2 finished: collect at utils.scala:41, took 0.009083 s
20/08/18 07:38:11 INFO InMemoryFileIndex: It took 22 ms to list leaf files for 1 paths.
20/08/18 07:39:14 INFO HiveMetaStore: 0: get_database: default
20/08/18 07:39:14 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 07:39:14 INFO HiveMetaStore: 0: get_database: default
20/08/18 07:39:14 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 07:39:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/08/18 07:39:14 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/08/18 07:39:14 INFO SparkContext: Starting job: collect at utils.scala:41
20/08/18 07:39:14 INFO DAGScheduler: Job 3 finished: collect at utils.scala:41, took 0.000436 s
20/08/18 08:02:10 INFO HiveMetaStore: 0: get_database: default
20/08/18 08:02:10 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 08:02:10 INFO HiveMetaStore: 0: get_database: default
20/08/18 08:02:10 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 08:02:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/08/18 08:02:10 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/08/18 08:02:10 INFO SparkContext: Starting job: collect at utils.scala:41
20/08/18 08:02:10 INFO DAGScheduler: Job 4 finished: collect at utils.scala:41, took 0.000240 s
20/08/18 08:02:11 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
20/08/18 08:02:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 297.3 KiB, free 912.0 MiB)
20/08/18 08:02:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.4 KiB, free 912.0 MiB)
20/08/18 08:02:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36565 (size: 24.4 KiB, free: 912.3 MiB)
20/08/18 08:02:11 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
20/08/18 08:02:12 INFO FileInputFormat: Total input paths to process : 1
20/08/18 08:02:12 INFO FileInputFormat: Total input paths to process : 1
20/08/18 08:02:12 INFO CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 2461049
20/08/18 08:02:12 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/08/18 08:02:12 INFO DAGScheduler: Got job 5 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/08/18 08:02:12 INFO DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)
20/08/18 08:02:12 INFO DAGScheduler: Parents of final stage: List()
20/08/18 08:02:12 INFO DAGScheduler: Missing parents: List()
20/08/18 08:02:12 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[32] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/08/18 08:02:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.2 KiB, free 912.0 MiB)
20/08/18 08:02:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 911.9 MiB)
20/08/18 08:02:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:36565 (size: 3.6 KiB, free: 912.3 MiB)
20/08/18 08:02:12 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
20/08/18 08:02:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[32] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/08/18 08:02:12 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/08/18 08:02:12 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7476 bytes)
20/08/18 08:02:12 INFO Executor: Running task 0.0 in stage 4.0 (TID 2)
20/08/18 08:02:13 INFO BinaryFileRDD: Input split: Paths:/home/emmanuel/R/Dissertation/okcupidData/profiles.csv:0+2461049
20/08/18 08:02:13 INFO Executor: Finished task 0.0 in stage 4.0 (TID 2). 1256 bytes result sent to driver
20/08/18 08:02:13 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 2) in 1333 ms on localhost (executor driver) (1/1)
20/08/18 08:02:13 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/08/18 08:02:13 INFO DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 1.406 s
20/08/18 08:02:13 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 08:02:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
20/08/18 08:02:13 INFO DAGScheduler: Job 5 finished: csv at NativeMethodAccessorImpl.java:0, took 1.420907 s
20/08/18 08:02:13 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:36565 in memory (size: 5.0 KiB, free: 912.3 MiB)
20/08/18 08:02:13 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/08/18 08:02:13 INFO DAGScheduler: Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/08/18 08:02:13 INFO DAGScheduler: Final stage: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0)
20/08/18 08:02:13 INFO DAGScheduler: Parents of final stage: List()
20/08/18 08:02:13 INFO DAGScheduler: Missing parents: List()
20/08/18 08:02:13 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[33] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/08/18 08:02:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.8 KiB, free 912.0 MiB)
20/08/18 08:02:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 911.9 MiB)
20/08/18 08:02:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:36565 (size: 4.6 KiB, free: 912.3 MiB)
20/08/18 08:02:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
20/08/18 08:02:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[33] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/08/18 08:02:13 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/08/18 08:02:13 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7476 bytes)
20/08/18 08:02:13 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
20/08/18 08:02:13 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:36565 in memory (size: 5.0 KiB, free: 912.3 MiB)
20/08/18 08:02:13 INFO BinaryFileRDD: Input split: Paths:/home/emmanuel/R/Dissertation/okcupidData/profiles.csv:0+2461049
20/08/18 08:02:14 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 1244 bytes result sent to driver
20/08/18 08:02:14 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 524 ms on localhost (executor driver) (1/1)
20/08/18 08:02:14 INFO DAGScheduler: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0) finished in 0.546 s
20/08/18 08:02:14 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 08:02:14 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/08/18 08:02:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
20/08/18 08:02:14 INFO DAGScheduler: Job 6 finished: csv at NativeMethodAccessorImpl.java:0, took 0.554533 s
20/08/18 08:02:15 INFO HiveMetaStore: 0: get_database: default
20/08/18 08:02:15 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 08:02:15 INFO HiveMetaStore: 0: get_database: default
20/08/18 08:02:15 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 08:02:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/08/18 08:02:15 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/08/18 08:02:15 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 08:02:15 INFO DAGScheduler: Registering RDD 36 (count at utils.scala:114) as input to shuffle 2
20/08/18 08:02:15 INFO DAGScheduler: Got job 7 (count at utils.scala:114) with 1 output partitions
20/08/18 08:02:15 INFO DAGScheduler: Final stage: ResultStage 7 (count at utils.scala:114)
20/08/18 08:02:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
20/08/18 08:02:15 INFO DAGScheduler: Missing parents: List()
20/08/18 08:02:15 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[39] at count at utils.scala:114), which has no missing parents
20/08/18 08:02:15 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 912.0 MiB)
20/08/18 08:02:15 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.9 MiB)
20/08/18 08:02:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:36565 (size: 5.0 KiB, free: 912.3 MiB)
20/08/18 08:02:15 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
20/08/18 08:02:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[39] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 08:02:15 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
20/08/18 08:02:15 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
20/08/18 08:02:15 INFO Executor: Running task 0.0 in stage 7.0 (TID 4)
20/08/18 08:02:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 08:02:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/08/18 08:02:15 INFO Executor: Finished task 0.0 in stage 7.0 (TID 4). 2641 bytes result sent to driver
20/08/18 08:02:15 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 15 ms on localhost (executor driver) (1/1)
20/08/18 08:02:15 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/08/18 08:02:15 INFO DAGScheduler: ResultStage 7 (count at utils.scala:114) finished in 0.023 s
20/08/18 08:02:15 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 08:02:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
20/08/18 08:02:15 INFO DAGScheduler: Job 7 finished: count at utils.scala:114, took 0.032134 s
20/08/18 08:02:16 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
20/08/18 08:02:17 INFO HiveMetaStore: 0: get_database: default
20/08/18 08:02:17 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 08:02:17 INFO HiveMetaStore: 0: get_database: default
20/08/18 08:02:17 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 08:02:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/08/18 08:02:17 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/08/18 08:02:17 INFO CodeGenerator: Code generated in 24.658614 ms
20/08/18 08:02:17 INFO CodeGenerator: Code generated in 41.570828 ms
20/08/18 08:02:17 INFO CodeGenerator: Code generated in 8.752317 ms
20/08/18 08:02:17 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 08:02:17 INFO DAGScheduler: Registering RDD 42 (count at utils.scala:114) as input to shuffle 3
20/08/18 08:02:17 INFO DAGScheduler: Got job 8 (count at utils.scala:114) with 1 output partitions
20/08/18 08:02:17 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:114)
20/08/18 08:02:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
20/08/18 08:02:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
20/08/18 08:02:17 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[42] at count at utils.scala:114), which has no missing parents
20/08/18 08:02:17 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.1 KiB, free 911.9 MiB)
20/08/18 08:02:17 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.9 MiB)
20/08/18 08:02:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:36565 (size: 5.3 KiB, free: 912.3 MiB)
20/08/18 08:02:17 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1200
20/08/18 08:02:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[42] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 08:02:17 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
20/08/18 08:02:17 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
20/08/18 08:02:17 INFO Executor: Running task 0.0 in stage 8.0 (TID 5)
20/08/18 08:02:17 INFO Executor: Finished task 0.0 in stage 8.0 (TID 5). 1876 bytes result sent to driver
20/08/18 08:02:17 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 109 ms on localhost (executor driver) (1/1)
20/08/18 08:02:17 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/08/18 08:02:17 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:114) finished in 0.153 s
20/08/18 08:02:17 INFO DAGScheduler: looking for newly runnable stages
20/08/18 08:02:17 INFO DAGScheduler: running: Set()
20/08/18 08:02:17 INFO DAGScheduler: waiting: Set(ResultStage 9)
20/08/18 08:02:17 INFO DAGScheduler: failed: Set()
20/08/18 08:02:17 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[45] at count at utils.scala:114), which has no missing parents
20/08/18 08:02:17 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 10.1 KiB, free 911.9 MiB)
20/08/18 08:02:17 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.9 MiB)
20/08/18 08:02:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:36565 (size: 5.0 KiB, free: 912.3 MiB)
20/08/18 08:02:17 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1200
20/08/18 08:02:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[45] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 08:02:17 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
20/08/18 08:02:17 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
20/08/18 08:02:17 INFO Executor: Running task 0.0 in stage 9.0 (TID 6)
20/08/18 08:02:17 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 08:02:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
20/08/18 08:02:17 INFO Executor: Finished task 0.0 in stage 9.0 (TID 6). 2648 bytes result sent to driver
20/08/18 08:02:17 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 50 ms on localhost (executor driver) (1/1)
20/08/18 08:02:17 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/08/18 08:02:17 INFO DAGScheduler: ResultStage 9 (count at utils.scala:114) finished in 0.064 s
20/08/18 08:02:17 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 08:02:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
20/08/18 08:02:17 INFO DAGScheduler: Job 8 finished: count at utils.scala:114, took 0.300421 s
20/08/18 08:04:48 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 08:04:48 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 08:04:48 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 08:04:48 INFO FileSourceStrategy: Output Data Schema: struct<age: int, body_type: string, diet: string, drinks: string, drugs: string ... 29 more fields>
20/08/18 08:04:48 INFO CodeGenerator: Code generated in 103.890268 ms
20/08/18 08:04:48 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 292.9 KiB, free 911.6 MiB)
20/08/18 08:04:48 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 911.6 MiB)
20/08/18 08:04:48 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 08:04:48 INFO SparkContext: Created broadcast 8 from collect at utils.scala:116
20/08/18 08:04:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 08:04:48 INFO SparkContext: Starting job: collect at utils.scala:116
20/08/18 08:04:48 INFO DAGScheduler: Got job 9 (collect at utils.scala:116) with 1 output partitions
20/08/18 08:04:48 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:116)
20/08/18 08:04:48 INFO DAGScheduler: Parents of final stage: List()
20/08/18 08:04:48 INFO DAGScheduler: Missing parents: List()
20/08/18 08:04:48 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[49] at collect at utils.scala:116), which has no missing parents
20/08/18 08:04:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 28.2 KiB, free 911.6 MiB)
20/08/18 08:04:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 911.6 MiB)
20/08/18 08:04:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:36565 (size: 9.7 KiB, free: 912.2 MiB)
20/08/18 08:04:48 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1200
20/08/18 08:04:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[49] at collect at utils.scala:116) (first 15 tasks are for partitions Vector(0))
20/08/18 08:04:48 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
20/08/18 08:04:48 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 7758 bytes)
20/08/18 08:04:48 INFO Executor: Running task 0.0 in stage 10.0 (TID 7)
20/08/18 08:04:48 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 08:04:48 INFO CodeGenerator: Code generated in 70.568245 ms
20/08/18 08:04:49 INFO Executor: Finished task 0.0 in stage 10.0 (TID 7). 89790 bytes result sent to driver
20/08/18 08:04:49 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 376 ms on localhost (executor driver) (1/1)
20/08/18 08:04:49 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/08/18 08:04:49 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:116) finished in 0.432 s
20/08/18 08:04:49 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 08:04:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
20/08/18 08:04:49 INFO DAGScheduler: Job 9 finished: collect at utils.scala:116, took 0.452011 s
20/08/18 08:04:49 INFO CodeGenerator: Code generated in 118.380568 ms
20/08/18 08:04:49 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 08:04:49 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 08:04:49 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 08:04:49 INFO FileSourceStrategy: Output Data Schema: struct<>
20/08/18 08:04:49 INFO CodeGenerator: Code generated in 24.401654 ms
20/08/18 08:04:49 INFO CodeGenerator: Code generated in 12.784259 ms
20/08/18 08:04:49 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 292.9 KiB, free 911.3 MiB)
20/08/18 08:04:49 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 911.3 MiB)
20/08/18 08:04:49 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 08:04:49 INFO SparkContext: Created broadcast 10 from count at utils.scala:114
20/08/18 08:04:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 08:04:49 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 08:04:49 INFO DAGScheduler: Registering RDD 53 (count at utils.scala:114) as input to shuffle 4
20/08/18 08:04:49 INFO DAGScheduler: Got job 10 (count at utils.scala:114) with 1 output partitions
20/08/18 08:04:49 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:114)
20/08/18 08:04:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
20/08/18 08:04:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
20/08/18 08:04:49 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[53] at count at utils.scala:114), which has no missing parents
20/08/18 08:04:49 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 911.2 MiB)
20/08/18 08:04:49 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 911.2 MiB)
20/08/18 08:04:49 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:36565 (size: 7.3 KiB, free: 912.2 MiB)
20/08/18 08:04:49 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1200
20/08/18 08:04:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[53] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 08:04:49 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
20/08/18 08:04:49 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 7747 bytes)
20/08/18 08:04:49 INFO Executor: Running task 0.0 in stage 11.0 (TID 8)
20/08/18 08:04:49 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 08:04:49 INFO Executor: Finished task 0.0 in stage 11.0 (TID 8). 1772 bytes result sent to driver
20/08/18 08:04:49 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 8) in 42 ms on localhost (executor driver) (1/1)
20/08/18 08:04:49 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/08/18 08:04:49 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:114) finished in 0.059 s
20/08/18 08:04:49 INFO DAGScheduler: looking for newly runnable stages
20/08/18 08:04:49 INFO DAGScheduler: running: Set()
20/08/18 08:04:49 INFO DAGScheduler: waiting: Set(ResultStage 12)
20/08/18 08:04:49 INFO DAGScheduler: failed: Set()
20/08/18 08:04:49 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[56] at count at utils.scala:114), which has no missing parents
20/08/18 08:04:49 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 11.5 KiB, free 911.2 MiB)
20/08/18 08:04:49 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.2 MiB)
20/08/18 08:04:49 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:36565 (size: 5.3 KiB, free: 912.2 MiB)
20/08/18 08:04:49 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1200
20/08/18 08:04:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[56] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 08:04:49 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
20/08/18 08:04:49 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
20/08/18 08:04:49 INFO Executor: Running task 0.0 in stage 12.0 (TID 9)
20/08/18 08:04:49 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 08:04:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/08/18 08:04:49 INFO Executor: Finished task 0.0 in stage 12.0 (TID 9). 2471 bytes result sent to driver
20/08/18 08:04:49 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 9) in 14 ms on localhost (executor driver) (1/1)
20/08/18 08:04:49 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/08/18 08:04:49 INFO DAGScheduler: ResultStage 12 (count at utils.scala:114) finished in 0.032 s
20/08/18 08:04:49 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 08:04:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
20/08/18 08:04:49 INFO DAGScheduler: Job 10 finished: count at utils.scala:114, took 0.097456 s
20/08/18 08:06:28 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:36565 in memory (size: 3.6 KiB, free: 912.2 MiB)
20/08/18 08:06:28 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:36565 in memory (size: 7.3 KiB, free: 912.2 MiB)
20/08/18 08:06:29 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 08:06:29 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 08:06:29 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:36565 in memory (size: 4.6 KiB, free: 912.2 MiB)
20/08/18 08:06:29 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:36565 in memory (size: 5.0 KiB, free: 912.3 MiB)
20/08/18 08:06:29 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:36565 in memory (size: 5.0 KiB, free: 912.3 MiB)
20/08/18 08:06:29 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:36565 in memory (size: 5.3 KiB, free: 912.3 MiB)
20/08/18 08:06:29 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:36565 in memory (size: 5.3 KiB, free: 912.3 MiB)
20/08/18 08:06:29 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:36565 in memory (size: 9.7 KiB, free: 912.3 MiB)
20/08/18 08:06:29 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:36565 in memory (size: 24.4 KiB, free: 912.3 MiB)
20/08/18 09:22:58 INFO HiveMetaStore: 0: get_database: default
20/08/18 09:22:58 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 09:22:58 INFO HiveMetaStore: 0: get_database: default
20/08/18 09:22:58 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 09:22:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/08/18 09:22:58 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/08/18 09:22:59 INFO CodeGenerator: Code generated in 14.22069 ms
20/08/18 09:22:59 INFO SparkContext: Starting job: collect at utils.scala:41
20/08/18 09:22:59 INFO DAGScheduler: Got job 11 (collect at utils.scala:41) with 1 output partitions
20/08/18 09:22:59 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:41)
20/08/18 09:22:59 INFO DAGScheduler: Parents of final stage: List()
20/08/18 09:22:59 INFO DAGScheduler: Missing parents: List()
20/08/18 09:22:59 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[62] at map at utils.scala:41), which has no missing parents
20/08/18 09:22:59 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.5 KiB, free 912.3 MiB)
20/08/18 09:22:59 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 912.3 MiB)
20/08/18 09:22:59 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:36565 (size: 4.5 KiB, free: 912.3 MiB)
20/08/18 09:22:59 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1200
20/08/18 09:22:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[62] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/08/18 09:22:59 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
20/08/18 09:22:59 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 7573 bytes)
20/08/18 09:22:59 INFO Executor: Running task 0.0 in stage 13.0 (TID 10)
20/08/18 09:23:00 INFO CodeGenerator: Code generated in 25.097647 ms
20/08/18 09:23:00 INFO Executor: Finished task 0.0 in stage 13.0 (TID 10). 1151 bytes result sent to driver
20/08/18 09:23:00 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 216 ms on localhost (executor driver) (1/1)
20/08/18 09:23:00 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/08/18 09:23:00 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:41) finished in 0.255 s
20/08/18 09:23:00 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 09:23:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
20/08/18 09:23:00 INFO DAGScheduler: Job 11 finished: collect at utils.scala:41, took 0.267368 s
20/08/18 09:23:01 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
20/08/18 09:23:01 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 297.3 KiB, free 912.0 MiB)
20/08/18 09:23:01 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 24.4 KiB, free 912.0 MiB)
20/08/18 09:23:01 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:36565 (size: 24.4 KiB, free: 912.3 MiB)
20/08/18 09:23:01 INFO SparkContext: Created broadcast 14 from csv at NativeMethodAccessorImpl.java:0
20/08/18 09:23:01 INFO FileInputFormat: Total input paths to process : 1
20/08/18 09:23:01 INFO FileInputFormat: Total input paths to process : 1
20/08/18 09:23:01 INFO CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 2461049
20/08/18 09:23:01 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/08/18 09:23:01 INFO DAGScheduler: Got job 12 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/08/18 09:23:01 INFO DAGScheduler: Final stage: ResultStage 14 (csv at NativeMethodAccessorImpl.java:0)
20/08/18 09:23:01 INFO DAGScheduler: Parents of final stage: List()
20/08/18 09:23:01 INFO DAGScheduler: Missing parents: List()
20/08/18 09:23:01 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[65] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/08/18 09:23:01 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 6.2 KiB, free 912.0 MiB)
20/08/18 09:23:01 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 912.0 MiB)
20/08/18 09:23:01 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:36565 (size: 3.6 KiB, free: 912.3 MiB)
20/08/18 09:23:01 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1200
20/08/18 09:23:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[65] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/08/18 09:23:01 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
20/08/18 09:23:01 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 7476 bytes)
20/08/18 09:23:01 INFO Executor: Running task 0.0 in stage 14.0 (TID 11)
20/08/18 09:23:01 INFO BinaryFileRDD: Input split: Paths:/home/emmanuel/R/Dissertation/okcupidData/profiles.csv:0+2461049
20/08/18 09:23:01 INFO Executor: Finished task 0.0 in stage 14.0 (TID 11). 1256 bytes result sent to driver
20/08/18 09:23:01 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 30 ms on localhost (executor driver) (1/1)
20/08/18 09:23:01 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
20/08/18 09:23:01 INFO DAGScheduler: ResultStage 14 (csv at NativeMethodAccessorImpl.java:0) finished in 0.038 s
20/08/18 09:23:01 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 09:23:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
20/08/18 09:23:01 INFO DAGScheduler: Job 12 finished: csv at NativeMethodAccessorImpl.java:0, took 0.040861 s
20/08/18 09:23:01 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/08/18 09:23:01 INFO DAGScheduler: Got job 13 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/08/18 09:23:01 INFO DAGScheduler: Final stage: ResultStage 15 (csv at NativeMethodAccessorImpl.java:0)
20/08/18 09:23:01 INFO DAGScheduler: Parents of final stage: List()
20/08/18 09:23:01 INFO DAGScheduler: Missing parents: List()
20/08/18 09:23:01 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[66] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/08/18 09:23:01 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 8.8 KiB, free 912.0 MiB)
20/08/18 09:23:01 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 912.0 MiB)
20/08/18 09:23:01 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:36565 (size: 4.6 KiB, free: 912.3 MiB)
20/08/18 09:23:01 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1200
20/08/18 09:23:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[66] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/08/18 09:23:01 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
20/08/18 09:23:01 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 7476 bytes)
20/08/18 09:23:01 INFO Executor: Running task 0.0 in stage 15.0 (TID 12)
20/08/18 09:23:01 INFO BinaryFileRDD: Input split: Paths:/home/emmanuel/R/Dissertation/okcupidData/profiles.csv:0+2461049
20/08/18 09:23:01 INFO Executor: Finished task 0.0 in stage 15.0 (TID 12). 1244 bytes result sent to driver
20/08/18 09:23:01 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 77 ms on localhost (executor driver) (1/1)
20/08/18 09:23:01 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
20/08/18 09:23:01 INFO DAGScheduler: ResultStage 15 (csv at NativeMethodAccessorImpl.java:0) finished in 0.090 s
20/08/18 09:23:01 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 09:23:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
20/08/18 09:23:01 INFO DAGScheduler: Job 13 finished: csv at NativeMethodAccessorImpl.java:0, took 0.095216 s
20/08/18 09:23:01 INFO HiveMetaStore: 0: get_database: default
20/08/18 09:23:01 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 09:23:01 INFO HiveMetaStore: 0: get_database: default
20/08/18 09:23:01 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 09:23:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/08/18 09:23:01 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/08/18 09:23:01 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 09:23:01 INFO DAGScheduler: Registering RDD 69 (count at utils.scala:114) as input to shuffle 5
20/08/18 09:23:01 INFO DAGScheduler: Got job 14 (count at utils.scala:114) with 1 output partitions
20/08/18 09:23:01 INFO DAGScheduler: Final stage: ResultStage 17 (count at utils.scala:114)
20/08/18 09:23:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
20/08/18 09:23:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
20/08/18 09:23:01 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[69] at count at utils.scala:114), which has no missing parents
20/08/18 09:23:01 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 10.1 KiB, free 911.9 MiB)
20/08/18 09:23:01 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.9 MiB)
20/08/18 09:23:01 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:36565 (size: 5.3 KiB, free: 912.3 MiB)
20/08/18 09:23:01 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1200
20/08/18 09:23:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[69] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 09:23:01 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
20/08/18 09:23:01 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
20/08/18 09:23:01 INFO Executor: Running task 0.0 in stage 16.0 (TID 13)
20/08/18 09:23:01 INFO Executor: Finished task 0.0 in stage 16.0 (TID 13). 1833 bytes result sent to driver
20/08/18 09:23:01 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 13) in 35 ms on localhost (executor driver) (1/1)
20/08/18 09:23:01 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
20/08/18 09:23:01 INFO DAGScheduler: ShuffleMapStage 16 (count at utils.scala:114) finished in 0.076 s
20/08/18 09:23:01 INFO DAGScheduler: looking for newly runnable stages
20/08/18 09:23:01 INFO DAGScheduler: running: Set()
20/08/18 09:23:01 INFO DAGScheduler: waiting: Set(ResultStage 17)
20/08/18 09:23:01 INFO DAGScheduler: failed: Set()
20/08/18 09:23:01 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at count at utils.scala:114), which has no missing parents
20/08/18 09:23:01 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 10.1 KiB, free 911.9 MiB)
20/08/18 09:23:01 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.9 MiB)
20/08/18 09:23:01 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:36565 (size: 5.0 KiB, free: 912.3 MiB)
20/08/18 09:23:01 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1200
20/08/18 09:23:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 09:23:01 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
20/08/18 09:23:01 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
20/08/18 09:23:01 INFO Executor: Running task 0.0 in stage 17.0 (TID 14)
20/08/18 09:23:01 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 09:23:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/08/18 09:23:01 INFO Executor: Finished task 0.0 in stage 17.0 (TID 14). 2648 bytes result sent to driver
20/08/18 09:23:01 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 14) in 25 ms on localhost (executor driver) (1/1)
20/08/18 09:23:01 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
20/08/18 09:23:01 INFO DAGScheduler: ResultStage 17 (count at utils.scala:114) finished in 0.038 s
20/08/18 09:23:01 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 09:23:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
20/08/18 09:23:01 INFO DAGScheduler: Job 14 finished: count at utils.scala:114, took 0.133516 s
20/08/18 09:23:03 INFO HiveMetaStore: 0: get_database: default
20/08/18 09:23:03 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 09:23:03 INFO HiveMetaStore: 0: get_database: default
20/08/18 09:23:03 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_database: default	
20/08/18 09:23:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/08/18 09:23:03 INFO audit: ugi=emmanuel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/08/18 09:23:03 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 09:23:03 INFO DAGScheduler: Registering RDD 75 (count at utils.scala:114) as input to shuffle 6
20/08/18 09:23:03 INFO DAGScheduler: Got job 15 (count at utils.scala:114) with 1 output partitions
20/08/18 09:23:03 INFO DAGScheduler: Final stage: ResultStage 19 (count at utils.scala:114)
20/08/18 09:23:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
20/08/18 09:23:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
20/08/18 09:23:03 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[75] at count at utils.scala:114), which has no missing parents
20/08/18 09:23:03 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 10.1 KiB, free 911.9 MiB)
20/08/18 09:23:03 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.9 MiB)
20/08/18 09:23:03 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:36565 (size: 5.3 KiB, free: 912.2 MiB)
20/08/18 09:23:03 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1200
20/08/18 09:23:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[75] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0, 1))
20/08/18 09:23:03 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
20/08/18 09:23:03 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
20/08/18 09:23:03 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 16, localhost, executor driver, partition 1, PROCESS_LOCAL, 7498 bytes)
20/08/18 09:23:03 INFO Executor: Running task 0.0 in stage 18.0 (TID 15)
20/08/18 09:23:03 INFO Executor: Running task 1.0 in stage 18.0 (TID 16)
20/08/18 09:23:03 INFO Executor: Finished task 0.0 in stage 18.0 (TID 15). 1833 bytes result sent to driver
20/08/18 09:23:03 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 15) in 15 ms on localhost (executor driver) (1/2)
20/08/18 09:23:03 INFO Executor: Finished task 1.0 in stage 18.0 (TID 16). 1833 bytes result sent to driver
20/08/18 09:23:03 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 16) in 41 ms on localhost (executor driver) (2/2)
20/08/18 09:23:03 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
20/08/18 09:23:03 INFO DAGScheduler: ShuffleMapStage 18 (count at utils.scala:114) finished in 0.055 s
20/08/18 09:23:03 INFO DAGScheduler: looking for newly runnable stages
20/08/18 09:23:03 INFO DAGScheduler: running: Set()
20/08/18 09:23:03 INFO DAGScheduler: waiting: Set(ResultStage 19)
20/08/18 09:23:03 INFO DAGScheduler: failed: Set()
20/08/18 09:23:03 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[78] at count at utils.scala:114), which has no missing parents
20/08/18 09:23:03 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 10.1 KiB, free 911.9 MiB)
20/08/18 09:23:03 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.9 MiB)
20/08/18 09:23:03 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:36565 (size: 5.0 KiB, free: 912.2 MiB)
20/08/18 09:23:03 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1200
20/08/18 09:23:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[78] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 09:23:03 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
20/08/18 09:23:03 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 17, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
20/08/18 09:23:03 INFO Executor: Running task 0.0 in stage 19.0 (TID 17)
20/08/18 09:23:03 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 09:23:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/08/18 09:23:03 INFO Executor: Finished task 0.0 in stage 19.0 (TID 17). 2648 bytes result sent to driver
20/08/18 09:23:03 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 17) in 26 ms on localhost (executor driver) (1/1)
20/08/18 09:23:03 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
20/08/18 09:23:03 INFO DAGScheduler: ResultStage 19 (count at utils.scala:114) finished in 0.042 s
20/08/18 09:23:03 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 09:23:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
20/08/18 09:23:03 INFO DAGScheduler: Job 15 finished: count at utils.scala:114, took 0.115294 s
20/08/18 09:23:17 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 09:23:17 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 09:23:17 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 09:23:17 INFO FileSourceStrategy: Output Data Schema: struct<age: int, body_type: string, diet: string, drinks: string, drugs: string ... 29 more fields>
20/08/18 09:23:17 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 292.9 KiB, free 911.6 MiB)
20/08/18 09:23:17 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 911.6 MiB)
20/08/18 09:23:17 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 09:23:17 INFO SparkContext: Created broadcast 21 from collect at utils.scala:116
20/08/18 09:23:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 09:23:17 INFO SparkContext: Starting job: collect at utils.scala:116
20/08/18 09:23:17 INFO DAGScheduler: Got job 16 (collect at utils.scala:116) with 1 output partitions
20/08/18 09:23:17 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:116)
20/08/18 09:23:17 INFO DAGScheduler: Parents of final stage: List()
20/08/18 09:23:17 INFO DAGScheduler: Missing parents: List()
20/08/18 09:23:17 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[82] at collect at utils.scala:116), which has no missing parents
20/08/18 09:23:17 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 28.2 KiB, free 911.6 MiB)
20/08/18 09:23:17 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 911.5 MiB)
20/08/18 09:23:17 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:36565 (size: 9.7 KiB, free: 912.2 MiB)
20/08/18 09:23:17 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1200
20/08/18 09:23:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[82] at collect at utils.scala:116) (first 15 tasks are for partitions Vector(0))
20/08/18 09:23:17 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
20/08/18 09:23:17 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 7758 bytes)
20/08/18 09:23:17 INFO Executor: Running task 0.0 in stage 20.0 (TID 18)
20/08/18 09:23:17 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 09:23:17 INFO Executor: Finished task 0.0 in stage 20.0 (TID 18). 89790 bytes result sent to driver
20/08/18 09:23:17 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 18) in 138 ms on localhost (executor driver) (1/1)
20/08/18 09:23:17 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
20/08/18 09:23:17 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:116) finished in 0.185 s
20/08/18 09:23:17 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 09:23:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
20/08/18 09:23:17 INFO DAGScheduler: Job 16 finished: collect at utils.scala:116, took 0.199419 s
20/08/18 09:23:18 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 09:23:18 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 09:23:18 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 09:23:18 INFO FileSourceStrategy: Output Data Schema: struct<>
20/08/18 09:23:18 INFO CodeGenerator: Code generated in 82.163158 ms
20/08/18 09:23:18 INFO CodeGenerator: Code generated in 42.76643 ms
20/08/18 09:23:18 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 292.9 KiB, free 911.3 MiB)
20/08/18 09:23:18 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 911.2 MiB)
20/08/18 09:23:18 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 09:23:18 INFO SparkContext: Created broadcast 23 from count at utils.scala:114
20/08/18 09:23:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 09:23:18 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 09:23:18 INFO DAGScheduler: Registering RDD 86 (count at utils.scala:114) as input to shuffle 7
20/08/18 09:23:18 INFO DAGScheduler: Got job 17 (count at utils.scala:114) with 1 output partitions
20/08/18 09:23:18 INFO DAGScheduler: Final stage: ResultStage 22 (count at utils.scala:114)
20/08/18 09:23:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
20/08/18 09:23:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
20/08/18 09:23:18 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[86] at count at utils.scala:114), which has no missing parents
20/08/18 09:23:18 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 14.4 KiB, free 911.2 MiB)
20/08/18 09:23:18 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 911.2 MiB)
20/08/18 09:23:18 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:36565 (size: 7.3 KiB, free: 912.2 MiB)
20/08/18 09:23:18 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1200
20/08/18 09:23:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[86] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 09:23:18 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
20/08/18 09:23:18 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 7747 bytes)
20/08/18 09:23:18 INFO Executor: Running task 0.0 in stage 21.0 (TID 19)
20/08/18 09:23:18 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 09:23:18 INFO Executor: Finished task 0.0 in stage 21.0 (TID 19). 1772 bytes result sent to driver
20/08/18 09:23:18 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 19) in 50 ms on localhost (executor driver) (1/1)
20/08/18 09:23:18 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
20/08/18 09:23:18 INFO DAGScheduler: ShuffleMapStage 21 (count at utils.scala:114) finished in 0.065 s
20/08/18 09:23:18 INFO DAGScheduler: looking for newly runnable stages
20/08/18 09:23:18 INFO DAGScheduler: running: Set()
20/08/18 09:23:18 INFO DAGScheduler: waiting: Set(ResultStage 22)
20/08/18 09:23:18 INFO DAGScheduler: failed: Set()
20/08/18 09:23:18 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at count at utils.scala:114), which has no missing parents
20/08/18 09:23:18 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 11.5 KiB, free 911.2 MiB)
20/08/18 09:23:18 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.2 MiB)
20/08/18 09:23:18 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:36565 (size: 5.3 KiB, free: 912.2 MiB)
20/08/18 09:23:18 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1200
20/08/18 09:23:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 09:23:18 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
20/08/18 09:23:18 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 20, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
20/08/18 09:23:18 INFO Executor: Running task 0.0 in stage 22.0 (TID 20)
20/08/18 09:23:18 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 09:23:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/08/18 09:23:18 INFO Executor: Finished task 0.0 in stage 22.0 (TID 20). 2471 bytes result sent to driver
20/08/18 09:23:18 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 20) in 14 ms on localhost (executor driver) (1/1)
20/08/18 09:23:18 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
20/08/18 09:23:18 INFO DAGScheduler: ResultStage 22 (count at utils.scala:114) finished in 0.034 s
20/08/18 09:23:18 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 09:23:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
20/08/18 09:23:18 INFO DAGScheduler: Job 17 finished: count at utils.scala:114, took 0.108666 s
20/08/18 09:27:06 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 09:27:06 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 09:27:06 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 09:27:06 INFO FileSourceStrategy: Output Data Schema: struct<essay0: string, essay1: string, essay2: string, essay3: string, essay4: string ... 8 more fields>
20/08/18 09:27:06 INFO CodeGenerator: Code generated in 13.844382 ms
20/08/18 09:27:06 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 292.9 KiB, free 910.9 MiB)
20/08/18 09:27:06 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 910.9 MiB)
20/08/18 09:27:06 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 09:27:06 INFO SparkContext: Created broadcast 26 from collect at utils.scala:116
20/08/18 09:27:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 09:27:06 INFO SparkContext: Starting job: collect at utils.scala:116
20/08/18 09:27:06 INFO DAGScheduler: Got job 18 (collect at utils.scala:116) with 1 output partitions
20/08/18 09:27:06 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:116)
20/08/18 09:27:06 INFO DAGScheduler: Parents of final stage: List()
20/08/18 09:27:06 INFO DAGScheduler: Missing parents: List()
20/08/18 09:27:06 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[93] at collect at utils.scala:116), which has no missing parents
20/08/18 09:27:06 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.1 KiB, free 910.9 MiB)
20/08/18 09:27:06 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 910.9 MiB)
20/08/18 09:27:06 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:36565 (size: 7.1 KiB, free: 912.1 MiB)
20/08/18 09:27:06 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1200
20/08/18 09:27:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[93] at collect at utils.scala:116) (first 15 tasks are for partitions Vector(0))
20/08/18 09:27:06 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
20/08/18 09:27:06 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 7758 bytes)
20/08/18 09:27:06 INFO Executor: Running task 0.0 in stage 23.0 (TID 21)
20/08/18 09:27:06 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 09:27:06 INFO CodeGenerator: Code generated in 15.04164 ms
20/08/18 09:27:06 INFO Executor: Finished task 0.0 in stage 23.0 (TID 21). 78221 bytes result sent to driver
20/08/18 09:27:06 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 21) in 39 ms on localhost (executor driver) (1/1)
20/08/18 09:27:06 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
20/08/18 09:27:06 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:116) finished in 0.048 s
20/08/18 09:27:06 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 09:27:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
20/08/18 09:27:06 INFO DAGScheduler: Job 18 finished: collect at utils.scala:116, took 0.051189 s
20/08/18 09:27:06 INFO CodeGenerator: Code generated in 13.850781 ms
20/08/18 09:27:07 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 09:27:07 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 09:27:07 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 09:27:07 INFO FileSourceStrategy: Output Data Schema: struct<>
20/08/18 09:27:07 INFO CodeGenerator: Code generated in 27.069726 ms
20/08/18 09:27:07 INFO CodeGenerator: Code generated in 11.35913 ms
20/08/18 09:27:07 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 292.9 KiB, free 910.6 MiB)
20/08/18 09:27:07 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 910.6 MiB)
20/08/18 09:27:07 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.1 MiB)
20/08/18 09:27:07 INFO SparkContext: Created broadcast 28 from count at utils.scala:114
20/08/18 09:27:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 09:27:07 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 09:27:07 INFO DAGScheduler: Registering RDD 97 (count at utils.scala:114) as input to shuffle 8
20/08/18 09:27:07 INFO DAGScheduler: Got job 19 (count at utils.scala:114) with 1 output partitions
20/08/18 09:27:07 INFO DAGScheduler: Final stage: ResultStage 25 (count at utils.scala:114)
20/08/18 09:27:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
20/08/18 09:27:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
20/08/18 09:27:07 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[97] at count at utils.scala:114), which has no missing parents
20/08/18 09:27:07 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 14.4 KiB, free 910.5 MiB)
20/08/18 09:27:07 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 910.5 MiB)
20/08/18 09:27:07 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:36565 (size: 7.3 KiB, free: 912.1 MiB)
20/08/18 09:27:07 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1200
20/08/18 09:27:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[97] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 09:27:07 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
20/08/18 09:27:07 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 7747 bytes)
20/08/18 09:27:07 INFO Executor: Running task 0.0 in stage 24.0 (TID 22)
20/08/18 09:27:07 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 09:27:07 INFO Executor: Finished task 0.0 in stage 24.0 (TID 22). 1772 bytes result sent to driver
20/08/18 09:27:07 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 22) in 35 ms on localhost (executor driver) (1/1)
20/08/18 09:27:07 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
20/08/18 09:27:07 INFO DAGScheduler: ShuffleMapStage 24 (count at utils.scala:114) finished in 0.054 s
20/08/18 09:27:07 INFO DAGScheduler: looking for newly runnable stages
20/08/18 09:27:07 INFO DAGScheduler: running: Set()
20/08/18 09:27:07 INFO DAGScheduler: waiting: Set(ResultStage 25)
20/08/18 09:27:07 INFO DAGScheduler: failed: Set()
20/08/18 09:27:07 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[100] at count at utils.scala:114), which has no missing parents
20/08/18 09:27:07 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 11.5 KiB, free 910.5 MiB)
20/08/18 09:27:07 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 910.5 MiB)
20/08/18 09:27:07 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:36565 (size: 5.3 KiB, free: 912.1 MiB)
20/08/18 09:27:07 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1200
20/08/18 09:27:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[100] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 09:27:07 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
20/08/18 09:27:07 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 23, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
20/08/18 09:27:07 INFO Executor: Running task 0.0 in stage 25.0 (TID 23)
20/08/18 09:27:07 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 09:27:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/08/18 09:27:07 INFO Executor: Finished task 0.0 in stage 25.0 (TID 23). 2471 bytes result sent to driver
20/08/18 09:27:07 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 23) in 19 ms on localhost (executor driver) (1/1)
20/08/18 09:27:07 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
20/08/18 09:27:07 INFO DAGScheduler: ResultStage 25 (count at utils.scala:114) finished in 0.027 s
20/08/18 09:27:07 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 09:27:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
20/08/18 09:27:07 INFO DAGScheduler: Job 19 finished: count at utils.scala:114, took 0.099553 s
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:36565 in memory (size: 7.3 KiB, free: 912.1 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.1 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:36565 in memory (size: 5.3 KiB, free: 912.1 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:36565 in memory (size: 3.6 KiB, free: 912.2 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:36565 in memory (size: 5.3 KiB, free: 912.2 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:36565 in memory (size: 5.0 KiB, free: 912.2 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:36565 in memory (size: 5.3 KiB, free: 912.2 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:36565 in memory (size: 5.0 KiB, free: 912.2 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:36565 in memory (size: 4.6 KiB, free: 912.2 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:36565 in memory (size: 7.1 KiB, free: 912.2 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:36565 in memory (size: 4.5 KiB, free: 912.2 MiB)
20/08/18 09:36:29 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:36565 in memory (size: 9.7 KiB, free: 912.2 MiB)
20/08/18 09:36:30 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.3 MiB)
20/08/18 09:36:30 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:36565 in memory (size: 5.3 KiB, free: 912.3 MiB)
20/08/18 09:36:30 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:36565 in memory (size: 7.3 KiB, free: 912.3 MiB)
20/08/18 09:36:30 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:36565 in memory (size: 24.4 KiB, free: 912.3 MiB)
20/08/18 10:01:40 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 10:01:40 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 10:01:40 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 10:01:40 INFO FileSourceStrategy: Output Data Schema: struct<essay0: string, essay1: string, essay2: string, essay3: string, essay4: string ... 8 more fields>
20/08/18 10:01:40 INFO CodeGenerator: Code generated in 175.649669 ms
20/08/18 10:01:40 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 292.9 KiB, free 912.0 MiB)
20/08/18 10:01:40 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 912.0 MiB)
20/08/18 10:01:40 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.3 MiB)
20/08/18 10:01:40 INFO SparkContext: Created broadcast 31 from collect at utils.scala:116
20/08/18 10:01:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 10:01:40 INFO SparkContext: Starting job: collect at utils.scala:116
20/08/18 10:01:40 INFO DAGScheduler: Got job 20 (collect at utils.scala:116) with 1 output partitions
20/08/18 10:01:40 INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:116)
20/08/18 10:01:40 INFO DAGScheduler: Parents of final stage: List()
20/08/18 10:01:40 INFO DAGScheduler: Missing parents: List()
20/08/18 10:01:40 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[104] at collect at utils.scala:116), which has no missing parents
20/08/18 10:01:40 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 59.1 KiB, free 911.9 MiB)
20/08/18 10:01:40 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 16.0 KiB, free 911.9 MiB)
20/08/18 10:01:40 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:36565 (size: 16.0 KiB, free: 912.3 MiB)
20/08/18 10:01:40 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1200
20/08/18 10:01:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[104] at collect at utils.scala:116) (first 15 tasks are for partitions Vector(0))
20/08/18 10:01:40 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
20/08/18 10:01:40 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 7758 bytes)
20/08/18 10:01:40 INFO Executor: Running task 0.0 in stage 26.0 (TID 24)
20/08/18 10:01:40 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 10:01:40 INFO Executor: Finished task 0.0 in stage 26.0 (TID 24). 136687 bytes result sent to driver
20/08/18 10:01:40 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 24) in 74 ms on localhost (executor driver) (1/1)
20/08/18 10:01:40 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
20/08/18 10:01:40 INFO DAGScheduler: ResultStage 26 (collect at utils.scala:116) finished in 0.091 s
20/08/18 10:01:40 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 10:01:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
20/08/18 10:01:40 INFO DAGScheduler: Job 20 finished: collect at utils.scala:116, took 0.104271 s
20/08/18 10:01:40 INFO CodeGenerator: Code generated in 29.019824 ms
20/08/18 10:01:40 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 10:01:40 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 10:01:40 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 10:01:40 INFO FileSourceStrategy: Output Data Schema: struct<>
20/08/18 10:01:40 INFO CodeGenerator: Code generated in 34.897462 ms
20/08/18 10:01:40 INFO CodeGenerator: Code generated in 11.990322 ms
20/08/18 10:01:40 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 292.9 KiB, free 911.6 MiB)
20/08/18 10:01:40 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 911.6 MiB)
20/08/18 10:01:40 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 10:01:40 INFO SparkContext: Created broadcast 33 from count at utils.scala:114
20/08/18 10:01:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 10:01:40 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 10:01:40 INFO DAGScheduler: Registering RDD 108 (count at utils.scala:114) as input to shuffle 9
20/08/18 10:01:40 INFO DAGScheduler: Got job 21 (count at utils.scala:114) with 1 output partitions
20/08/18 10:01:40 INFO DAGScheduler: Final stage: ResultStage 28 (count at utils.scala:114)
20/08/18 10:01:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
20/08/18 10:01:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
20/08/18 10:01:40 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[108] at count at utils.scala:114), which has no missing parents
20/08/18 10:01:40 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 14.4 KiB, free 911.6 MiB)
20/08/18 10:01:40 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 911.6 MiB)
20/08/18 10:01:40 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:36565 (size: 7.3 KiB, free: 912.2 MiB)
20/08/18 10:01:40 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1200
20/08/18 10:01:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[108] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 10:01:40 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
20/08/18 10:01:40 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 7747 bytes)
20/08/18 10:01:40 INFO Executor: Running task 0.0 in stage 27.0 (TID 25)
20/08/18 10:01:40 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 10:01:40 INFO Executor: Finished task 0.0 in stage 27.0 (TID 25). 1772 bytes result sent to driver
20/08/18 10:01:40 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 25) in 30 ms on localhost (executor driver) (1/1)
20/08/18 10:01:40 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
20/08/18 10:01:40 INFO DAGScheduler: ShuffleMapStage 27 (count at utils.scala:114) finished in 0.040 s
20/08/18 10:01:40 INFO DAGScheduler: looking for newly runnable stages
20/08/18 10:01:40 INFO DAGScheduler: running: Set()
20/08/18 10:01:40 INFO DAGScheduler: waiting: Set(ResultStage 28)
20/08/18 10:01:40 INFO DAGScheduler: failed: Set()
20/08/18 10:01:40 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[111] at count at utils.scala:114), which has no missing parents
20/08/18 10:01:40 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 11.5 KiB, free 911.6 MiB)
20/08/18 10:01:40 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.6 MiB)
20/08/18 10:01:40 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:36565 (size: 5.3 KiB, free: 912.2 MiB)
20/08/18 10:01:40 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1200
20/08/18 10:01:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[111] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 10:01:40 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
20/08/18 10:01:40 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 26, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
20/08/18 10:01:40 INFO Executor: Running task 0.0 in stage 28.0 (TID 26)
20/08/18 10:01:40 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 10:01:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/08/18 10:01:40 INFO Executor: Finished task 0.0 in stage 28.0 (TID 26). 2471 bytes result sent to driver
20/08/18 10:01:40 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 26) in 14 ms on localhost (executor driver) (1/1)
20/08/18 10:01:40 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
20/08/18 10:01:40 INFO DAGScheduler: ResultStage 28 (count at utils.scala:114) finished in 0.026 s
20/08/18 10:01:40 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 10:01:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
20/08/18 10:01:40 INFO DAGScheduler: Job 21 finished: count at utils.scala:114, took 0.075163 s
20/08/18 10:02:59 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 10:02:59 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 10:02:59 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 10:02:59 INFO FileSourceStrategy: Output Data Schema: struct<essay0: string, essay1: string, essay2: string, essay3: string, essay4: string ... 8 more fields>
20/08/18 10:02:59 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 292.9 KiB, free 911.3 MiB)
20/08/18 10:02:59 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 911.3 MiB)
20/08/18 10:02:59 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 10:02:59 INFO SparkContext: Created broadcast 36 from collect at utils.scala:116
20/08/18 10:02:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 10:02:59 INFO SparkContext: Starting job: collect at utils.scala:116
20/08/18 10:02:59 INFO DAGScheduler: Got job 22 (collect at utils.scala:116) with 1 output partitions
20/08/18 10:02:59 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:116)
20/08/18 10:02:59 INFO DAGScheduler: Parents of final stage: List()
20/08/18 10:02:59 INFO DAGScheduler: Missing parents: List()
20/08/18 10:02:59 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[115] at collect at utils.scala:116), which has no missing parents
20/08/18 10:02:59 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 16.1 KiB, free 911.2 MiB)
20/08/18 10:02:59 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 911.2 MiB)
20/08/18 10:02:59 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:36565 (size: 7.1 KiB, free: 912.2 MiB)
20/08/18 10:02:59 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1200
20/08/18 10:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[115] at collect at utils.scala:116) (first 15 tasks are for partitions Vector(0))
20/08/18 10:02:59 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
20/08/18 10:02:59 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 7758 bytes)
20/08/18 10:02:59 INFO Executor: Running task 0.0 in stage 29.0 (TID 27)
20/08/18 10:02:59 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 10:02:59 INFO Executor: Finished task 0.0 in stage 29.0 (TID 27). 78221 bytes result sent to driver
20/08/18 10:02:59 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 27) in 21 ms on localhost (executor driver) (1/1)
20/08/18 10:02:59 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
20/08/18 10:02:59 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:116) finished in 0.032 s
20/08/18 10:02:59 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 10:02:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
20/08/18 10:02:59 INFO DAGScheduler: Job 22 finished: collect at utils.scala:116, took 0.034615 s
20/08/18 10:02:59 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 10:02:59 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 10:02:59 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 10:02:59 INFO FileSourceStrategy: Output Data Schema: struct<>
20/08/18 10:02:59 INFO CodeGenerator: Code generated in 12.075635 ms
20/08/18 10:02:59 INFO CodeGenerator: Code generated in 6.503898 ms
20/08/18 10:02:59 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 292.9 KiB, free 911.0 MiB)
20/08/18 10:02:59 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 910.9 MiB)
20/08/18 10:02:59 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 10:02:59 INFO SparkContext: Created broadcast 38 from count at utils.scala:114
20/08/18 10:02:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 10:02:59 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 10:02:59 INFO DAGScheduler: Registering RDD 119 (count at utils.scala:114) as input to shuffle 10
20/08/18 10:02:59 INFO DAGScheduler: Got job 23 (count at utils.scala:114) with 1 output partitions
20/08/18 10:02:59 INFO DAGScheduler: Final stage: ResultStage 31 (count at utils.scala:114)
20/08/18 10:02:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
20/08/18 10:02:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 30)
20/08/18 10:02:59 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[119] at count at utils.scala:114), which has no missing parents
20/08/18 10:02:59 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 14.4 KiB, free 910.9 MiB)
20/08/18 10:02:59 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 910.9 MiB)
20/08/18 10:02:59 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:36565 (size: 7.3 KiB, free: 912.2 MiB)
20/08/18 10:02:59 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1200
20/08/18 10:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[119] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 10:02:59 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
20/08/18 10:02:59 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 7747 bytes)
20/08/18 10:02:59 INFO Executor: Running task 0.0 in stage 30.0 (TID 28)
20/08/18 10:02:59 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 10:02:59 INFO Executor: Finished task 0.0 in stage 30.0 (TID 28). 1772 bytes result sent to driver
20/08/18 10:02:59 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 28) in 29 ms on localhost (executor driver) (1/1)
20/08/18 10:02:59 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
20/08/18 10:02:59 INFO DAGScheduler: ShuffleMapStage 30 (count at utils.scala:114) finished in 0.054 s
20/08/18 10:02:59 INFO DAGScheduler: looking for newly runnable stages
20/08/18 10:02:59 INFO DAGScheduler: running: Set()
20/08/18 10:02:59 INFO DAGScheduler: waiting: Set(ResultStage 31)
20/08/18 10:02:59 INFO DAGScheduler: failed: Set()
20/08/18 10:02:59 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[122] at count at utils.scala:114), which has no missing parents
20/08/18 10:02:59 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 11.5 KiB, free 910.9 MiB)
20/08/18 10:02:59 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 910.9 MiB)
20/08/18 10:02:59 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:36565 (size: 5.3 KiB, free: 912.2 MiB)
20/08/18 10:02:59 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1200
20/08/18 10:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[122] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 10:02:59 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
20/08/18 10:02:59 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 29, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
20/08/18 10:02:59 INFO Executor: Running task 0.0 in stage 31.0 (TID 29)
20/08/18 10:02:59 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 10:02:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/08/18 10:02:59 INFO Executor: Finished task 0.0 in stage 31.0 (TID 29). 2471 bytes result sent to driver
20/08/18 10:02:59 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 29) in 18 ms on localhost (executor driver) (1/1)
20/08/18 10:02:59 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
20/08/18 10:02:59 INFO DAGScheduler: ResultStage 31 (count at utils.scala:114) finished in 0.032 s
20/08/18 10:02:59 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 10:02:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
20/08/18 10:02:59 INFO DAGScheduler: Job 23 finished: count at utils.scala:114, took 0.090942 s
20/08/18 10:05:11 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 10:05:11 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 10:05:11 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 10:05:11 INFO FileSourceStrategy: Output Data Schema: struct<essay0: string, essay1: string, essay2: string, essay3: string, essay4: string ... 8 more fields>
20/08/18 10:05:11 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 292.9 KiB, free 910.6 MiB)
20/08/18 10:05:11 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 910.6 MiB)
20/08/18 10:05:11 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.1 MiB)
20/08/18 10:05:11 INFO SparkContext: Created broadcast 41 from collect at utils.scala:116
20/08/18 10:05:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 10:05:11 INFO SparkContext: Starting job: collect at utils.scala:116
20/08/18 10:05:11 INFO DAGScheduler: Got job 24 (collect at utils.scala:116) with 1 output partitions
20/08/18 10:05:11 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:116)
20/08/18 10:05:11 INFO DAGScheduler: Parents of final stage: List()
20/08/18 10:05:11 INFO DAGScheduler: Missing parents: List()
20/08/18 10:05:11 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[126] at collect at utils.scala:116), which has no missing parents
20/08/18 10:05:11 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 16.1 KiB, free 910.6 MiB)
20/08/18 10:05:11 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 910.6 MiB)
20/08/18 10:05:11 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:36565 (size: 7.1 KiB, free: 912.1 MiB)
20/08/18 10:05:11 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1200
20/08/18 10:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[126] at collect at utils.scala:116) (first 15 tasks are for partitions Vector(0))
20/08/18 10:05:11 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
20/08/18 10:05:11 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 7758 bytes)
20/08/18 10:05:11 INFO Executor: Running task 0.0 in stage 32.0 (TID 30)
20/08/18 10:05:11 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 10:05:11 INFO Executor: Finished task 0.0 in stage 32.0 (TID 30). 78221 bytes result sent to driver
20/08/18 10:05:11 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 30) in 24 ms on localhost (executor driver) (1/1)
20/08/18 10:05:11 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
20/08/18 10:05:11 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:116) finished in 0.040 s
20/08/18 10:05:11 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 10:05:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
20/08/18 10:05:11 INFO DAGScheduler: Job 24 finished: collect at utils.scala:116, took 0.043233 s
20/08/18 10:05:11 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 10:05:11 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 10:05:11 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 10:05:11 INFO FileSourceStrategy: Output Data Schema: struct<>
20/08/18 10:05:11 INFO CodeGenerator: Code generated in 24.525885 ms
20/08/18 10:05:11 INFO CodeGenerator: Code generated in 7.665504 ms
20/08/18 10:05:11 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 292.9 KiB, free 910.3 MiB)
20/08/18 10:05:11 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 910.2 MiB)
20/08/18 10:05:11 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.1 MiB)
20/08/18 10:05:11 INFO SparkContext: Created broadcast 43 from count at utils.scala:114
20/08/18 10:05:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 10:05:11 INFO SparkContext: Starting job: count at utils.scala:114
20/08/18 10:05:11 INFO DAGScheduler: Registering RDD 130 (count at utils.scala:114) as input to shuffle 11
20/08/18 10:05:11 INFO DAGScheduler: Got job 25 (count at utils.scala:114) with 1 output partitions
20/08/18 10:05:11 INFO DAGScheduler: Final stage: ResultStage 34 (count at utils.scala:114)
20/08/18 10:05:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
20/08/18 10:05:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
20/08/18 10:05:11 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[130] at count at utils.scala:114), which has no missing parents
20/08/18 10:05:11 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 14.4 KiB, free 910.2 MiB)
20/08/18 10:05:11 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 910.2 MiB)
20/08/18 10:05:11 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:36565 (size: 7.3 KiB, free: 912.1 MiB)
20/08/18 10:05:11 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1200
20/08/18 10:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[130] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 10:05:11 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
20/08/18 10:05:11 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 7747 bytes)
20/08/18 10:05:11 INFO Executor: Running task 0.0 in stage 33.0 (TID 31)
20/08/18 10:05:11 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 10:05:11 INFO Executor: Finished task 0.0 in stage 33.0 (TID 31). 1772 bytes result sent to driver
20/08/18 10:05:11 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 31) in 18 ms on localhost (executor driver) (1/1)
20/08/18 10:05:11 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
20/08/18 10:05:11 INFO DAGScheduler: ShuffleMapStage 33 (count at utils.scala:114) finished in 0.029 s
20/08/18 10:05:11 INFO DAGScheduler: looking for newly runnable stages
20/08/18 10:05:11 INFO DAGScheduler: running: Set()
20/08/18 10:05:11 INFO DAGScheduler: waiting: Set(ResultStage 34)
20/08/18 10:05:11 INFO DAGScheduler: failed: Set()
20/08/18 10:05:11 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[133] at count at utils.scala:114), which has no missing parents
20/08/18 10:05:11 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 11.5 KiB, free 910.2 MiB)
20/08/18 10:05:11 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 910.2 MiB)
20/08/18 10:05:11 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:36565 (size: 5.3 KiB, free: 912.1 MiB)
20/08/18 10:05:11 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1200
20/08/18 10:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[133] at count at utils.scala:114) (first 15 tasks are for partitions Vector(0))
20/08/18 10:05:11 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
20/08/18 10:05:11 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 32, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
20/08/18 10:05:11 INFO Executor: Running task 0.0 in stage 34.0 (TID 32)
20/08/18 10:05:11 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 10:05:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/08/18 10:05:11 INFO Executor: Finished task 0.0 in stage 34.0 (TID 32). 2471 bytes result sent to driver
20/08/18 10:05:11 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 32) in 40 ms on localhost (executor driver) (1/1)
20/08/18 10:05:11 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
20/08/18 10:05:11 INFO DAGScheduler: ResultStage 34 (count at utils.scala:114) finished in 0.049 s
20/08/18 10:05:11 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 10:05:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
20/08/18 10:05:11 INFO DAGScheduler: Job 25 finished: count at utils.scala:114, took 0.088211 s
20/08/18 10:06:28 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:36565 in memory (size: 5.3 KiB, free: 912.1 MiB)
20/08/18 10:06:28 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:36565 in memory (size: 7.3 KiB, free: 912.1 MiB)
20/08/18 10:06:28 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:36565 in memory (size: 5.3 KiB, free: 912.1 MiB)
20/08/18 10:06:28 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.1 MiB)
20/08/18 10:06:28 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 10:06:28 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 10:06:28 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:36565 in memory (size: 7.1 KiB, free: 912.2 MiB)
20/08/18 10:06:29 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:36565 in memory (size: 7.1 KiB, free: 912.2 MiB)
20/08/18 10:06:29 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 10:06:29 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:36565 in memory (size: 5.3 KiB, free: 912.2 MiB)
20/08/18 10:06:29 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:36565 in memory (size: 7.3 KiB, free: 912.2 MiB)
20/08/18 10:06:29 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.3 MiB)
20/08/18 10:06:29 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.3 MiB)
20/08/18 10:06:29 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:36565 in memory (size: 16.0 KiB, free: 912.3 MiB)
20/08/18 10:06:29 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:36565 in memory (size: 7.3 KiB, free: 912.3 MiB)
20/08/18 13:37:31 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 13:37:31 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 13:37:31 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 13:37:31 INFO FileSourceStrategy: Output Data Schema: struct<essay0: string, essay1: string, essay2: string, essay3: string, essay4: string ... 8 more fields>
20/08/18 13:37:31 INFO CodeGenerator: Code generated in 60.271149 ms
20/08/18 13:37:31 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 292.9 KiB, free 912.0 MiB)
20/08/18 13:37:31 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 912.0 MiB)
20/08/18 13:37:31 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.3 MiB)
20/08/18 13:37:31 INFO SparkContext: Created broadcast 46 from rdd at CountVectorizer.scala:191
20/08/18 13:37:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 13:37:31 INFO SparkContext: Starting job: count at CountVectorizer.scala:233
20/08/18 13:37:31 INFO DAGScheduler: Registering RDD 141 (flatMap at CountVectorizer.scala:212) as input to shuffle 12
20/08/18 13:37:31 INFO DAGScheduler: Got job 26 (count at CountVectorizer.scala:233) with 1 output partitions
20/08/18 13:37:31 INFO DAGScheduler: Final stage: ResultStage 36 (count at CountVectorizer.scala:233)
20/08/18 13:37:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
20/08/18 13:37:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
20/08/18 13:37:31 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[141] at flatMap at CountVectorizer.scala:212), which has no missing parents
20/08/18 13:37:31 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 53.9 KiB, free 911.9 MiB)
20/08/18 13:37:31 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 21.2 KiB, free 911.9 MiB)
20/08/18 13:37:31 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:36565 (size: 21.2 KiB, free: 912.3 MiB)
20/08/18 13:37:31 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1200
20/08/18 13:37:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[141] at flatMap at CountVectorizer.scala:212) (first 15 tasks are for partitions Vector(0))
20/08/18 13:37:31 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
20/08/18 13:37:31 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 7747 bytes)
20/08/18 13:37:31 INFO Executor: Running task 0.0 in stage 35.0 (TID 33)
20/08/18 13:37:32 INFO CodeGenerator: Code generated in 48.776552 ms
20/08/18 13:37:32 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 13:37:34 INFO Executor: Finished task 0.0 in stage 35.0 (TID 33). 1905 bytes result sent to driver
20/08/18 13:37:34 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 33) in 2399 ms on localhost (executor driver) (1/1)
20/08/18 13:37:34 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
20/08/18 13:37:34 INFO DAGScheduler: ShuffleMapStage 35 (flatMap at CountVectorizer.scala:212) finished in 2.833 s
20/08/18 13:37:34 INFO DAGScheduler: looking for newly runnable stages
20/08/18 13:37:34 INFO DAGScheduler: running: Set()
20/08/18 13:37:34 INFO DAGScheduler: waiting: Set(ResultStage 36)
20/08/18 13:37:34 INFO DAGScheduler: failed: Set()
20/08/18 13:37:34 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[144] at map at CountVectorizer.scala:230), which has no missing parents
20/08/18 13:37:34 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 5.3 KiB, free 911.9 MiB)
20/08/18 13:37:34 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 911.9 MiB)
20/08/18 13:37:34 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:36565 (size: 2.8 KiB, free: 912.3 MiB)
20/08/18 13:37:34 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1200
20/08/18 13:37:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[144] at map at CountVectorizer.scala:230) (first 15 tasks are for partitions Vector(0))
20/08/18 13:37:34 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
20/08/18 13:37:34 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 34, localhost, executor driver, partition 0, NODE_LOCAL, 7143 bytes)
20/08/18 13:37:34 INFO Executor: Running task 0.0 in stage 36.0 (TID 34)
20/08/18 13:37:34 INFO ShuffleBlockFetcherIterator: Getting 1 (234.8 KiB) non-empty blocks including 1 (234.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/08/18 13:37:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/08/18 13:37:34 INFO MemoryStore: Block rdd_144_0 stored as values in memory (estimated size 398.0 KiB, free 911.5 MiB)
20/08/18 13:37:34 INFO BlockManagerInfo: Added rdd_144_0 in memory on localhost:36565 (size: 398.0 KiB, free: 911.9 MiB)
20/08/18 13:37:34 INFO Executor: Finished task 0.0 in stage 36.0 (TID 34). 1305 bytes result sent to driver
20/08/18 13:37:34 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 34) in 313 ms on localhost (executor driver) (1/1)
20/08/18 13:37:34 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
20/08/18 13:37:34 INFO DAGScheduler: ResultStage 36 (count at CountVectorizer.scala:233) finished in 0.329 s
20/08/18 13:37:34 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 13:37:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
20/08/18 13:37:34 INFO DAGScheduler: Job 26 finished: count at CountVectorizer.scala:233, took 3.176972 s
20/08/18 13:37:34 INFO SparkContext: Starting job: top at CountVectorizer.scala:236
20/08/18 13:37:34 INFO DAGScheduler: Got job 27 (top at CountVectorizer.scala:236) with 1 output partitions
20/08/18 13:37:34 INFO DAGScheduler: Final stage: ResultStage 38 (top at CountVectorizer.scala:236)
20/08/18 13:37:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
20/08/18 13:37:34 INFO DAGScheduler: Missing parents: List()
20/08/18 13:37:34 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[145] at top at CountVectorizer.scala:236), which has no missing parents
20/08/18 13:37:34 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 6.3 KiB, free 911.5 MiB)
20/08/18 13:37:34 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 911.5 MiB)
20/08/18 13:37:34 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:36565 (size: 3.3 KiB, free: 911.9 MiB)
20/08/18 13:37:34 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1200
20/08/18 13:37:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[145] at top at CountVectorizer.scala:236) (first 15 tasks are for partitions Vector(0))
20/08/18 13:37:34 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
20/08/18 13:37:34 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 7143 bytes)
20/08/18 13:37:34 INFO Executor: Running task 0.0 in stage 38.0 (TID 35)
20/08/18 13:37:34 INFO BlockManager: Found block rdd_144_0 locally
20/08/18 13:37:34 INFO Executor: Finished task 0.0 in stage 38.0 (TID 35). 101044 bytes result sent to driver
20/08/18 13:37:34 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 35) in 98 ms on localhost (executor driver) (1/1)
20/08/18 13:37:34 INFO DAGScheduler: ResultStage 38 (top at CountVectorizer.scala:236) finished in 0.131 s
20/08/18 13:37:34 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 13:37:34 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
20/08/18 13:37:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
20/08/18 13:37:34 INFO DAGScheduler: Job 27 finished: top at CountVectorizer.scala:236, took 0.139763 s
20/08/18 13:37:34 INFO MapPartitionsRDD: Removing RDD 144 from persistence list
20/08/18 13:37:34 INFO BlockManager: Removing RDD 144
20/08/18 13:37:35 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 652.8 KiB, free 911.3 MiB)
20/08/18 13:37:35 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 50.1 KiB, free 911.2 MiB)
20/08/18 13:37:35 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:36565 (size: 50.1 KiB, free: 912.2 MiB)
20/08/18 13:37:35 INFO SparkContext: Created broadcast 50 from broadcast at CountVectorizer.scala:306
20/08/18 13:37:35 INFO Instrumentation: [5016a666] training finished
20/08/18 13:37:35 INFO Instrumentation: [638d3359] training finished
20/08/18 13:37:35 INFO Instrumentation: [8a049a9c] Stage class: LDA
20/08/18 13:37:35 INFO Instrumentation: [8a049a9c] Stage uid: lda__238ee76f_afb1_4c77_8619_a4e8527c7747
20/08/18 13:37:36 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 13:37:36 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 13:37:36 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 13:37:36 INFO FileSourceStrategy: Output Data Schema: struct<essay0: string, essay1: string, essay2: string, essay3: string, essay4: string ... 8 more fields>
20/08/18 13:37:36 INFO BlockManagerInfo: Removed broadcast_47_piece0 on localhost:36565 in memory (size: 21.2 KiB, free: 912.2 MiB)
20/08/18 13:37:36 INFO BlockManagerInfo: Removed broadcast_48_piece0 on localhost:36565 in memory (size: 2.8 KiB, free: 912.2 MiB)
20/08/18 13:37:36 INFO BlockManager: Removing RDD 144
20/08/18 13:37:36 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:36565 in memory (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 13:37:36 INFO BlockManagerInfo: Removed broadcast_49_piece0 on localhost:36565 in memory (size: 3.3 KiB, free: 912.3 MiB)
20/08/18 13:37:36 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$ is 16553 bytes
20/08/18 13:37:36 INFO CodeGenerator: Code generated in 353.146924 ms
20/08/18 13:37:36 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 292.9 KiB, free 911.3 MiB)
20/08/18 13:37:36 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 911.3 MiB)
20/08/18 13:37:36 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 13:37:36 INFO SparkContext: Created broadcast 51 from rdd at Instrumentation.scala:62
20/08/18 13:37:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 13:37:36 INFO Instrumentation: [8a049a9c] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
20/08/18 13:37:36 INFO Instrumentation: [8a049a9c] {"optimizer":"online","keepLastCheckpoint":true,"subsamplingRate":0.05,"topicDistributionCol":"topicDistribution","featuresCol":"features","learningDecay":0.51,"checkpointInterval":10,"learningOffset":1024.0,"optimizeDocConcentration":true,"maxIter":1,"k":6}
20/08/18 13:37:37 INFO FileSourceStrategy: Pruning directories with: 
20/08/18 13:37:37 INFO FileSourceStrategy: Pushed Filters: 
20/08/18 13:37:37 INFO FileSourceStrategy: Post-Scan Filters: 
20/08/18 13:37:37 INFO FileSourceStrategy: Output Data Schema: struct<essay0: string, essay1: string, essay2: string, essay3: string, essay4: string ... 8 more fields>
20/08/18 13:37:37 INFO CodeGenerator: Code generated in 24.206875 ms
20/08/18 13:37:37 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 292.9 KiB, free 911.0 MiB)
20/08/18 13:37:37 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 911.0 MiB)
20/08/18 13:37:37 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:36565 (size: 24.3 KiB, free: 912.2 MiB)
20/08/18 13:37:37 INFO SparkContext: Created broadcast 52 from rdd at LDA.scala:999
20/08/18 13:37:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/08/18 13:37:37 INFO SparkContext: Starting job: count at LDAOptimizer.scala:413
20/08/18 13:37:37 INFO DAGScheduler: Got job 28 (count at LDAOptimizer.scala:413) with 1 output partitions
20/08/18 13:37:37 INFO DAGScheduler: Final stage: ResultStage 39 (count at LDAOptimizer.scala:413)
20/08/18 13:37:37 INFO DAGScheduler: Parents of final stage: List()
20/08/18 13:37:37 INFO DAGScheduler: Missing parents: List()
20/08/18 13:37:37 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[158] at map at LDA.scala:1001), which has no missing parents
20/08/18 13:37:37 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 795.7 KiB, free 910.2 MiB)
20/08/18 13:37:37 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 139.6 KiB, free 910.1 MiB)
20/08/18 13:37:37 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:36565 (size: 139.6 KiB, free: 912.1 MiB)
20/08/18 13:37:37 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1200
20/08/18 13:37:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[158] at map at LDA.scala:1001) (first 15 tasks are for partitions Vector(0))
20/08/18 13:37:37 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
20/08/18 13:37:37 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 7758 bytes)
20/08/18 13:37:37 INFO Executor: Running task 0.0 in stage 39.0 (TID 36)
20/08/18 13:37:37 INFO CodeGenerator: Code generated in 21.3255 ms
20/08/18 13:37:37 INFO FileScanRDD: Reading File path: file:///home/emmanuel/R/Dissertation/okcupidData/profiles.csv, range: 0-2461049, partition values: [empty row]
20/08/18 13:37:39 INFO MemoryStore: Block rdd_158_0 stored as values in memory (estimated size 1406.9 KiB, free 908.7 MiB)
20/08/18 13:37:39 INFO BlockManagerInfo: Added rdd_158_0 in memory on localhost:36565 (size: 1406.9 KiB, free: 910.7 MiB)
20/08/18 13:37:39 INFO Executor: Finished task 0.0 in stage 39.0 (TID 36). 1622 bytes result sent to driver
20/08/18 13:37:39 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 36) in 1700 ms on localhost (executor driver) (1/1)
20/08/18 13:37:39 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
20/08/18 13:37:39 INFO DAGScheduler: ResultStage 39 (count at LDAOptimizer.scala:413) finished in 1.825 s
20/08/18 13:37:39 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 13:37:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
20/08/18 13:37:39 INFO DAGScheduler: Job 28 finished: count at LDAOptimizer.scala:413, took 1.842633 s
20/08/18 13:37:39 INFO SparkContext: Starting job: first at LDAOptimizer.scala:414
20/08/18 13:37:39 INFO DAGScheduler: Got job 29 (first at LDAOptimizer.scala:414) with 1 output partitions
20/08/18 13:37:39 INFO DAGScheduler: Final stage: ResultStage 40 (first at LDAOptimizer.scala:414)
20/08/18 13:37:39 INFO DAGScheduler: Parents of final stage: List()
20/08/18 13:37:39 INFO DAGScheduler: Missing parents: List()
20/08/18 13:37:39 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[158] at map at LDA.scala:1001), which has no missing parents
20/08/18 13:37:39 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 795.8 KiB, free 907.9 MiB)
20/08/18 13:37:39 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 139.6 KiB, free 907.8 MiB)
20/08/18 13:37:39 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:36565 (size: 139.6 KiB, free: 910.6 MiB)
20/08/18 13:37:39 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1200
20/08/18 13:37:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[158] at map at LDA.scala:1001) (first 15 tasks are for partitions Vector(0))
20/08/18 13:37:39 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
20/08/18 13:37:39 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 7758 bytes)
20/08/18 13:37:39 INFO Executor: Running task 0.0 in stage 40.0 (TID 37)
20/08/18 13:37:39 INFO BlockManager: Found block rdd_158_0 locally
20/08/18 13:37:39 INFO Executor: 1 block locks were not released by TID = 37:
[rdd_158_0]
20/08/18 13:37:39 INFO Executor: Finished task 0.0 in stage 40.0 (TID 37). 3023 bytes result sent to driver
20/08/18 13:37:39 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 37) in 47 ms on localhost (executor driver) (1/1)
20/08/18 13:37:39 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
20/08/18 13:37:39 INFO DAGScheduler: ResultStage 40 (first at LDAOptimizer.scala:414) finished in 0.074 s
20/08/18 13:37:39 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 13:37:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
20/08/18 13:37:39 INFO DAGScheduler: Job 29 finished: first at LDAOptimizer.scala:414, took 0.077903 s
20/08/18 13:37:40 INFO SparkContext: Starting job: isEmpty at LDAOptimizer.scala:448
20/08/18 13:37:40 INFO DAGScheduler: Got job 30 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
20/08/18 13:37:40 INFO DAGScheduler: Final stage: ResultStage 41 (isEmpty at LDAOptimizer.scala:448)
20/08/18 13:37:40 INFO DAGScheduler: Parents of final stage: List()
20/08/18 13:37:40 INFO DAGScheduler: Missing parents: List()
20/08/18 13:37:40 INFO DAGScheduler: Submitting ResultStage 41 (PartitionwiseSampledRDD[159] at sample at LDAOptimizer.scala:447), which has no missing parents
20/08/18 13:37:40 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 812.6 KiB, free 907.0 MiB)
20/08/18 13:37:40 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 148.4 KiB, free 906.9 MiB)
20/08/18 13:37:40 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:36565 (size: 148.4 KiB, free: 910.4 MiB)
20/08/18 13:37:40 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1200
20/08/18 13:37:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (PartitionwiseSampledRDD[159] at sample at LDAOptimizer.scala:447) (first 15 tasks are for partitions Vector(0))
20/08/18 13:37:40 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
20/08/18 13:37:40 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7867 bytes)
20/08/18 13:37:40 INFO Executor: Running task 0.0 in stage 41.0 (TID 38)
20/08/18 13:37:40 INFO BlockManager: Found block rdd_158_0 locally
20/08/18 13:37:40 INFO Executor: 1 block locks were not released by TID = 38:
[rdd_158_0]
20/08/18 13:37:40 INFO Executor: Finished task 0.0 in stage 41.0 (TID 38). 2015 bytes result sent to driver
20/08/18 13:37:40 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 38) in 28 ms on localhost (executor driver) (1/1)
20/08/18 13:37:40 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
20/08/18 13:37:40 INFO DAGScheduler: ResultStage 41 (isEmpty at LDAOptimizer.scala:448) finished in 0.055 s
20/08/18 13:37:40 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 13:37:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
20/08/18 13:37:40 INFO DAGScheduler: Job 30 finished: isEmpty at LDAOptimizer.scala:448, took 0.058304 s
20/08/18 13:37:41 INFO BlockManagerInfo: Removed broadcast_55_piece0 on localhost:36565 in memory (size: 148.4 KiB, free: 910.6 MiB)
20/08/18 13:37:41 INFO BlockManagerInfo: Removed broadcast_53_piece0 on localhost:36565 in memory (size: 139.6 KiB, free: 910.7 MiB)
20/08/18 13:37:41 INFO BlockManagerInfo: Removed broadcast_54_piece0 on localhost:36565 in memory (size: 139.6 KiB, free: 910.8 MiB)
20/08/18 13:37:41 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 216.2 KiB, free 909.4 MiB)
20/08/18 13:37:41 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 216.5 KiB, free 909.2 MiB)
20/08/18 13:37:41 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:36565 (size: 216.5 KiB, free: 910.6 MiB)
20/08/18 13:37:41 INFO SparkContext: Created broadcast 56 from broadcast at LDAOptimizer.scala:462
20/08/18 13:37:41 INFO SparkContext: Starting job: treeAggregate at LDAOptimizer.scala:502
20/08/18 13:37:41 INFO DAGScheduler: Got job 31 (treeAggregate at LDAOptimizer.scala:502) with 1 output partitions
20/08/18 13:37:41 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at LDAOptimizer.scala:502)
20/08/18 13:37:41 INFO DAGScheduler: Parents of final stage: List()
20/08/18 13:37:41 INFO DAGScheduler: Missing parents: List()
20/08/18 13:37:41 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[161] at treeAggregate at LDAOptimizer.scala:502), which has no missing parents
20/08/18 13:37:41 WARN DAGScheduler: Broadcasting large task binary with size 1246.7 KiB
20/08/18 13:37:41 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 1246.8 KiB, free 908.0 MiB)
20/08/18 13:37:41 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 151.6 KiB, free 907.8 MiB)
20/08/18 13:37:41 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:36565 (size: 151.6 KiB, free: 910.5 MiB)
20/08/18 13:37:41 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1200
20/08/18 13:37:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[161] at treeAggregate at LDAOptimizer.scala:502) (first 15 tasks are for partitions Vector(0))
20/08/18 13:37:41 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
20/08/18 13:37:41 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 7867 bytes)
20/08/18 13:37:41 INFO Executor: Running task 0.0 in stage 42.0 (TID 39)
20/08/18 13:37:41 INFO BlockManager: Found block rdd_158_0 locally
20/08/18 13:37:41 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
20/08/18 13:37:41 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
20/08/18 13:37:42 INFO Executor: Finished task 0.0 in stage 42.0 (TID 39). 224505 bytes result sent to driver
20/08/18 13:37:42 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 39) in 912 ms on localhost (executor driver) (1/1)
20/08/18 13:37:42 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
20/08/18 13:37:42 INFO DAGScheduler: ResultStage 42 (treeAggregate at LDAOptimizer.scala:502) finished in 0.964 s
20/08/18 13:37:42 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
20/08/18 13:37:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
20/08/18 13:37:42 INFO DAGScheduler: Job 31 finished: treeAggregate at LDAOptimizer.scala:502, took 0.967460 s
20/08/18 13:37:42 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at LDAOptimizer.scala:506)
20/08/18 13:37:42 INFO BlockManagerInfo: Removed broadcast_56_piece0 on localhost:36565 in memory (size: 216.5 KiB, free: 910.7 MiB)
20/08/18 13:37:42 INFO MapPartitionsRDD: Removing RDD 158 from persistence list
20/08/18 13:37:42 INFO Instrumentation: [8a049a9c] {"numFeatures":4610}
20/08/18 13:37:42 INFO Instrumentation: [8a049a9c] training finished
20/08/18 13:37:42 INFO Instrumentation: [fd490bac] training finished
20/08/18 13:37:42 INFO BlockManager: Removing RDD 158
20/08/18 14:04:55 INFO SparkContext: Invoking stop() from shutdown hook
20/08/18 14:04:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
20/08/18 14:04:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/08/18 14:04:55 INFO MemoryStore: MemoryStore cleared
20/08/18 14:04:55 INFO BlockManager: BlockManager stopped
20/08/18 14:04:55 INFO BlockManagerMaster: BlockManagerMaster stopped
20/08/18 14:04:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/08/18 14:04:55 INFO SparkContext: Successfully stopped SparkContext
20/08/18 14:04:55 INFO ShutdownHookManager: Shutdown hook called
20/08/18 14:04:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-49bc0bb0-178b-479f-8e72-5b785b2a6aee
20/08/18 14:04:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-06406bd7-240b-4c8d-8ead-d460bc7da82a
